{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  2.4.0+cu121\n",
      "Torchvision Version:  0.19.0+cu121\n"
     ]
    }
   ],
   "source": [
    "# From: https://www.kaggle.com/c/dog-breed-identification/data\n",
    "# Author: Morpheus Hsieh\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import os, sys\n",
    "import copy\n",
    "import io\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from os import listdir\n",
    "from os.path import join, isfile, split, exists\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:\n",
      "{\n",
      "    \"DataPath\": \"/home/jovyan/data/dog-breed/\",\n",
      "    \"OutPath\": \"/home/jovyan/output/dog-breed/\",\n",
      "    \"ProcPath\": \"/home/jovyan/output/dog-breed/\",\n",
      "    \"PreTrainPath\": \"/home/jovyan/models/dog-breed/\",\n",
      "    \"PreTrainFile\": \"resnet50_20240801-2306_acc88.pth\",\n",
      "    \"TestPath\": \"/home/jovyan/data/dog-breed/test\",\n",
      "    \"TrainPath\": \"/home/jovyan/data/dog-breed/train\",\n",
      "    \"CsvLabel\": \"labels.csv\",\n",
      "    \"BatchSize\": 16,\n",
      "    \"FracForTrain\": 0.8\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Load parameters from json file\n",
    "\n",
    "# OutPath = r'D:\\GitWork\\dog_breed\\output'\n",
    "OutPath = '/home/jovyan/output/dog-breed/'\n",
    "\n",
    "# cfgPath = r'D:\\GitWork\\dog_breed\\configs'\n",
    "# fname = 'Params_20200923-2230.json'\n",
    "# json_file = join(cfgPath, fname)\n",
    "\n",
    "# with open(json_file) as fin: \n",
    "#     Params = json.load(fin) \n",
    "\n",
    "# Params = {\n",
    "#     'DataPath'    : r'D:\\GitWork\\dog_breed\\data',\n",
    "#     'OutPath'     : r'D:\\GitWork\\dog_breed\\output',\n",
    "#     'ProcPath'    : r'D:\\GitWork\\dog_breed\\processed',\n",
    "#     'PreTrainPath': r'D:\\GitWork\\dog_breed\\pretrained',\n",
    "#     'TestPath'    : r'D:\\Dataset\\dog-breed-identification\\test',\n",
    "#     'TrainPath'   : r'D:\\Dataset\\dog-breed-identification\\train',\n",
    "#     'PreTrainFile': 'resnet50_20200926-2053_t9175_v9339.pth',\n",
    "#     'CsvLabel'    : 'labels.csv',\n",
    "#     'BatchSize'   : 16,\n",
    "#     'FracForTrain': 0.8\n",
    "# }\n",
    "\n",
    "Params = {\n",
    "    'DataPath'    : r'/home/jovyan/data/dog-breed/',\n",
    "    'OutPath'     : r'/home/jovyan/output/dog-breed/',\n",
    "    'ProcPath'    : r'/home/jovyan/output/dog-breed/',\n",
    "    'PreTrainPath': r'/home/jovyan/models/dog-breed/',\n",
    "    'PreTrainFile': r'resnet50_20240801-2306_acc88.pth',\n",
    "    'TestPath'    : r'/home/jovyan/data/dog-breed/test',\n",
    "    'TrainPath'   : r'/home/jovyan/data/dog-breed/train',\n",
    "    'CsvLabel'    : 'labels.csv',\n",
    "    'BatchSize'   : 16,\n",
    "    'FracForTrain': 0.8\n",
    "}\n",
    "\n",
    "print('Parameters:')\n",
    "print(json.dumps(Params, indent=4))\n",
    "\n",
    "PreTranPath = Params['PreTrainPath']\n",
    "PreTranFile = Params['PreTrainFile']\n",
    "Pretrain_abspath = join(PreTranPath, PreTranFile)\n",
    "\n",
    "if not exists(Pretrain_abspath) or not isfile(Pretrain_abspath):\n",
    "    outstr = \"\\n'{}' model not found...\".format(Pretrain_abspath)\n",
    "    print(outstr)\n",
    "    raise SystemExit(outstr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10222 entries, 0 to 10221\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      10222 non-null  object\n",
      " 1   breed   10222 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 159.8+ KB\n",
      "None\n",
      "\n",
      "                                 id             breed\n",
      "0  000bec180eb18c7604dcecc8fe0dba07       boston_bull\n",
      "1  001513dfcb2ffafc82cccf4d8bbaba97             dingo\n",
      "2  001cdf01b096e06d78e9e5112d419397          pekinese\n",
      "3  00214f311d5d2247d5dfe4fe24b2303d          bluetick\n",
      "4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever\n",
      "\n",
      "Num classes: 10222\n"
     ]
    }
   ],
   "source": [
    "# Read labels information\n",
    "\n",
    "DataPath = Params.get('DataPath')\n",
    "csv_labels = Params.get('CsvLabel')\n",
    "f_abspath = join(DataPath, csv_labels)\n",
    "\n",
    "df_labels = pd.read_csv(f_abspath)\n",
    "\n",
    "print(df_labels.info())\n",
    "print(); print(df_labels.head())\n",
    "\n",
    "NumClasses = df_labels.shape[0]\n",
    "print('\\nNum classes:', NumClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120 entries, 0 to 119\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   breed_id  120 non-null    int64 \n",
      " 1   breed     120 non-null    object\n",
      " 2   count     120 non-null    int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 2.9+ KB\n",
      "None\n",
      "\n",
      "   breed_id                 breed  count\n",
      "0         0    scottish_deerhound    126\n",
      "1         1           maltese_dog    117\n",
      "2         2          afghan_hound    116\n",
      "3         3           entlebucher    115\n",
      "4         4  bernese_mountain_dog    114\n",
      "\n",
      "Num classes: 120\n",
      "\n",
      "Breeds dict backward:\n",
      "{\n",
      "  0: scottish_deerhound\n",
      "  1: maltese_dog\n",
      "  2: afghan_hound\n",
      "  3: entlebucher\n",
      "  4: bernese_mountain_dog\n",
      "  5: shih-tzu\n",
      "  6: great_pyrenees\n",
      "  7: pomeranian\n",
      "  8: basenji\n",
      "  9: samoyed\n",
      "  10: airedale\n",
      "  11: tibetan_terrier\n",
      "  12: leonberg\n",
      "  13: cairn\n",
      "  14: beagle\n",
      "  15: japanese_spaniel\n",
      "  16: australian_terrier\n",
      "  17: blenheim_spaniel\n",
      "  18: miniature_pinscher\n",
      "  19: irish_wolfhound\n",
      "  20: lakeland_terrier\n",
      "  21: saluki\n",
      "  22: papillon\n",
      "  23: whippet\n",
      "  24: siberian_husky\n",
      "  25: norwegian_elkhound\n",
      "  26: pug\n",
      "  27: chow\n",
      "  28: italian_greyhound\n",
      "  29: pembroke\n",
      "  30: ibizan_hound\n",
      "  31: border_terrier\n",
      "  32: newfoundland\n",
      "  33: lhasa\n",
      "  34: silky_terrier\n",
      "  35: bedlington_terrier\n",
      "  36: dandie_dinmont\n",
      "  37: irish_setter\n",
      "  38: sealyham_terrier\n",
      "  39: rhodesian_ridgeback\n",
      "  40: old_english_sheepdog\n",
      "  41: collie\n",
      "  42: boston_bull\n",
      "  43: english_foxhound\n",
      "  44: bouvier_des_flandres\n",
      "  45: african_hunting_dog\n",
      "  46: schipperke\n",
      "  47: kelpie\n",
      "  48: weimaraner\n",
      "  49: bloodhound\n",
      "  50: bluetick\n",
      "  51: saint_bernard\n",
      "  52: labrador_retriever\n",
      "  53: chesapeake_bay_retriever\n",
      "  54: norfolk_terrier\n",
      "  55: english_setter\n",
      "  56: wire-haired_fox_terrier\n",
      "  57: kerry_blue_terrier\n",
      "  58: scotch_terrier\n",
      "  59: yorkshire_terrier\n",
      "  60: groenendael\n",
      "  61: greater_swiss_mountain_dog\n",
      "  62: irish_terrier\n",
      "  63: basset\n",
      "  64: keeshond\n",
      "  65: west_highland_white_terrier\n",
      "  66: gordon_setter\n",
      "  67: malamute\n",
      "  68: affenpinscher\n",
      "  69: toy_poodle\n",
      "  70: clumber\n",
      "  71: mexican_hairless\n",
      "  72: dingo\n",
      "  73: standard_poodle\n",
      "  74: miniature_poodle\n",
      "  75: staffordshire_bullterrier\n",
      "  76: welsh_springer_spaniel\n",
      "  77: toy_terrier\n",
      "  78: sussex_spaniel\n",
      "  79: norwich_terrier\n",
      "  80: appenzeller\n",
      "  81: irish_water_spaniel\n",
      "  82: miniature_schnauzer\n",
      "  83: black-and-tan_coonhound\n",
      "  84: cardigan\n",
      "  85: dhole\n",
      "  86: shetland_sheepdog\n",
      "  87: rottweiler\n",
      "  88: english_springer\n",
      "  89: great_dane\n",
      "  90: german_short-haired_pointer\n",
      "  91: boxer\n",
      "  92: bull_mastiff\n",
      "  93: borzoi\n",
      "  94: pekinese\n",
      "  95: cocker_spaniel\n",
      "  96: american_staffordshire_terrier\n",
      "  97: doberman\n",
      "  98: brittany_spaniel\n",
      "  99: malinois\n",
      "  100: standard_schnauzer\n",
      "  101: flat-coated_retriever\n",
      "  102: redbone\n",
      "  103: border_collie\n",
      "  104: curly-coated_retriever\n",
      "  105: kuvasz\n",
      "  106: chihuahua\n",
      "  107: soft-coated_wheaten_terrier\n",
      "  108: french_bulldog\n",
      "  109: vizsla\n",
      "  110: tibetan_mastiff\n",
      "  111: german_shepherd\n",
      "  112: giant_schnauzer\n",
      "  113: walker_hound\n",
      "  114: otterhound\n",
      "  115: golden_retriever\n",
      "  116: brabancon_griffon\n",
      "  117: komondor\n",
      "  118: briard\n",
      "  119: eskimo_dog\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Count all breeds\n",
    "def countBreeds(df):\n",
    "    df1 = df_labels.groupby(\"breed\")[\"id\"].count().reset_index(name=\"count\")\n",
    "    df1 = df1.sort_values(by='count', ascending=False).reset_index(drop=True)\n",
    "    df1.insert(0, 'breed_id', df1.index)\n",
    "    return df1\n",
    "\n",
    "df_breeds = countBreeds(df_labels)\n",
    "print(df_breeds.info())\n",
    "print(); print(df_breeds.head())\n",
    "\n",
    "NumClasses = int(df_breeds.shape[0])\n",
    "print('\\nNum classes:', NumClasses)\n",
    "\n",
    "selected_breeds = df_breeds['breed'].tolist()\n",
    "\n",
    "# dict_bid_fw = dict(df_breeds[['breed', 'breed_id']].values)\n",
    "dict_bid_bw = dict(df_breeds[['breed_id', 'breed']].values)\n",
    "\n",
    "def prettyPrint(d, indent=0):\n",
    "    print('{')\n",
    "    for key, value in d.items():\n",
    "        if isinstance(value, dict):\n",
    "            print('  ' * indent + str(key))\n",
    "            prettyPrint(value, indent+1)\n",
    "        else:\n",
    "            print('  ' * (indent+1) + f\"{key}: {value}\")\n",
    "    print('}')\n",
    "                \n",
    "print('\\nBreeds dict backward:'); \n",
    "prettyPrint(dict_bid_bw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image shape: torch.Size([100, 3, 224, 224])\n",
      "\n",
      "Image ids\n",
      "  e458d6133dd1b436b047f86910f7fe34\n",
      "  635e859fef2e4cfaf5546c4d0265c88e\n",
      "  944ec36bc768ee309e51bf881dabcb15\n",
      "  616bf51988ee33e53d0e96c2367594fb\n",
      "  6c834ba0465f70e9abb2629864530b64\n",
      "  6899f99568a71ffa7d0affe51b759c23\n",
      "  e7afb35b8252782013a6700e28e327fa\n",
      "  cb808a3e412ab8cb51e69ae07bd1d6fe\n",
      "  07ad25df7e380e29aa4a5788a96cef73\n",
      "  03205e3e568c87e1568a8415272a8da4\n",
      "  114cdd56bf41af845a83404b1a57ab82\n",
      "  76e0cd14e2485f3b87abd6b7363400e8\n",
      "  d786274a5042d9f222833b8dd38d0550\n",
      "  18dba93ad1e08a88aa83c3c8d58a5429\n",
      "  19905a98817ec6df4765ad5713558a76\n",
      "  769df36b2485b3e9df740ca8e9e49793\n",
      "  48dfb3ec4a4247325478e1c33c0d1683\n",
      "  85819cf427f6e9806a16b087a1622c5a\n",
      "  0cb0cc50ad302ff64f3297ce361ec485\n",
      "  3ada400595a24fb5ff3c1fab4dea1581\n",
      "  291d224aac9198f9c314fed2d247b34e\n",
      "  9e72af813948e3349bc6b3454b4a6e52\n",
      "  84590d2967993bf557e99de3d20658cd\n",
      "  4f7ec53fb020dfd90ac36227ab8233dc\n",
      "  fa85d9951d7996c4c92ce5dc41d87dcd\n",
      "  c364569a4a1eba0dd82f4ae244e60aeb\n",
      "  85f5f54e24db0bb9b2a44e37f67ad60d\n",
      "  058449b1062e42da9c45cb434c69d647\n",
      "  ca9f2b11a817dbbe6fa9c81a9e8b0108\n",
      "  11f1d13042c0409b87fb39414f189e52\n",
      "  22e505cea377535bb668f3f8fa745464\n",
      "  9897c9664a743e57ec7f2e0cdb1bc255\n",
      "  30acb7d3ea82b6dd0e099fbf42065212\n",
      "  c87b574003ac9568970b70f29702bf85\n",
      "  bb2aa1afdc136526d1ae856b99d820b4\n",
      "  ae5e61b0582f6f0b6c2405048e9772e6\n",
      "  104dcfea5f3ab572029acae587e42a79\n",
      "  873dc1b114bc51a7d186d95d4c6e582d\n",
      "  486f3cc1d1324b8633278ef97719cab6\n",
      "  5f0689f1454032a485c455101b4cf2ec\n",
      "  d4f5c15370f69fdd190acc3247595b08\n",
      "  2db034155afba138269547667f7982a6\n",
      "  e5fa615e36dc3b2b3f554aa5097a6ece\n",
      "  1edc9d0814654106f79ec57747ada6a3\n",
      "  522176333469973f74ea9cbb18eea2eb\n",
      "  583f7580fa5fec1266331fcf83b76fd6\n",
      "  5716bb0eadd6fb29fa059721c9d15905\n",
      "  0c8afe874cdaa93402af403b8720cdbe\n",
      "  dfe02d52ca281aaca6215a42fee6245c\n",
      "  fc346bf7b0b6af0646a34a73ee8aa4b7\n",
      "  ec89476b99aab390011acee436f9642a\n",
      "  c8da818ea5e06b5c22a9d5d053896927\n",
      "  1d1c000670c98e32cb04f97d338be910\n",
      "  e6d6ff5b33e6174158d5ab05a7eda95c\n",
      "  13802b88269d75c9bda1c8a2489abc5c\n",
      "  a284b9f86363d779c3642f7effc0e59f\n",
      "  23b15493751b54bd911efd99d25bd808\n",
      "  1dd6f1c84e794b45c533aae5a36ffc3d\n",
      "  b151fa5a434c3a7fcc6618c8d6a0797a\n",
      "  b7da7e682c407ed8a8da93ab0cce3821\n",
      "  e427b9e1ab1b7f09cfb02ac073f56f2d\n",
      "  ff9742bc22b5830176e85490cf54cdf7\n",
      "  0e38176c43c4bfc1db5433fe4d607f1e\n",
      "  cf64016d08aacd4e9b6af996aa2deda9\n",
      "  86b0ea086d876d9c92dd58432c85c993\n",
      "  6dc8b801689473766e8ce04031c6bf31\n",
      "  8ab2c099a5ffb7e5b9781c4e4317a4fe\n",
      "  74a50646dfd99459faf8c1a626c53795\n",
      "  d73332e902de7569ca81511c89ea029a\n",
      "  cc5f9b543a724d7c24b8fa6b52834e40\n",
      "  44fe931a1d976f1e90c088ccff31f8cb\n",
      "  16cd0ecab645b8d0629296fe0ee728f0\n",
      "  da316b3810125758e911850b9c389ce9\n",
      "  f90032fc6036df7fab8f6fda5be69824\n",
      "  036205f601ec9fc663c913fdb92fa012\n",
      "  2f8ea7b3242838538dba2a258b3a24fe\n",
      "  ccbb9dd96ed2b8a635b4389eb85c6c96\n",
      "  0fb4de8ba53b256e5b66d432c347ba92\n",
      "  951963ef2007503c39f82ee2cd968b7c\n",
      "  3a74533c75d7d581b76322398bcb5fd6\n",
      "  eac3503b463e275d9f3053b8fcd5a58a\n",
      "  86a881909386141aa388d0b2dbd386f1\n",
      "  1b9121c8fbee846206fa96bf90066b0e\n",
      "  b9aecb05c7f833a31f5e7e9399812332\n",
      "  2913036c550a533b77a53bdff3da43db\n",
      "  f2b7d11ea6ccf65f214cac2abee8d1a1\n",
      "  c7cdafe94af0cdacba94aac48dd46e51\n",
      "  b4cc00474a2631ce06ea48e088d1d92d\n",
      "  cbec48a7350a78e419b5fc1e4068b98f\n",
      "  966d92071cc9c8268e8169c80eebb8c7\n",
      "  91629164463a0e1bf61cab33e96f66b5\n",
      "  6c959ab8926c4699bcab8bb414b6a78f\n",
      "  000621fb3cbb32d8935728e48679680e\n",
      "  5333ccb08620f8f0855750adc4138c27\n",
      "  1be1d95cc9cea3c8cc1b0b31a4ac9a4c\n",
      "  79ab5c9545fdca6831f527daf80c6d44\n",
      "  b484aabdb7f4b0495e1dc4df26fba764\n",
      "  200364801b15793809948e0b2a08567e\n",
      "  b1cd742b8e651699372c104b0ee50ce0\n",
      "  6a2cfab843ba8a78ab3f179a56b9d8e2\n",
      "\n",
      "Image shape: torch.Size([3, 224, 224])\n",
      "\n",
      "Image tensor:\n",
      "tensor([[[0.9216, 0.8745, 0.8588,  ..., 0.8235, 0.7569, 0.8235],\n",
      "         [0.7843, 0.4078, 0.4039,  ..., 0.3020, 0.2980, 0.6941],\n",
      "         [0.7961, 0.4275, 0.7373,  ..., 0.7333, 0.3490, 0.6941],\n",
      "         ...,\n",
      "         [0.7176, 0.3725, 0.7333,  ..., 0.6314, 0.4353, 0.8353],\n",
      "         [0.7529, 0.3098, 0.5333,  ..., 0.3020, 0.4000, 0.8706],\n",
      "         [0.9059, 0.8353, 0.8431,  ..., 0.8000, 0.8353, 0.9333]],\n",
      "\n",
      "        [[0.9412, 0.9059, 0.9098,  ..., 0.8510, 0.8235, 0.8863],\n",
      "         [0.8118, 0.4431, 0.4549,  ..., 0.3804, 0.3843, 0.7569],\n",
      "         [0.8353, 0.4667, 0.7686,  ..., 0.7686, 0.4196, 0.7647],\n",
      "         ...,\n",
      "         [0.7569, 0.4078, 0.7608,  ..., 0.6392, 0.4627, 0.8667],\n",
      "         [0.7765, 0.3373, 0.5686,  ..., 0.3333, 0.4275, 0.8980],\n",
      "         [0.9176, 0.8588, 0.8824,  ..., 0.8353, 0.8627, 0.9569]],\n",
      "\n",
      "        [[0.8275, 0.8039, 0.8157,  ..., 0.7843, 0.7333, 0.8000],\n",
      "         [0.7098, 0.3529, 0.3725,  ..., 0.2941, 0.2863, 0.6706],\n",
      "         [0.7490, 0.3882, 0.7098,  ..., 0.7020, 0.3255, 0.6745],\n",
      "         ...,\n",
      "         [0.6745, 0.3255, 0.6784,  ..., 0.5686, 0.3804, 0.7804],\n",
      "         [0.6980, 0.2667, 0.4863,  ..., 0.2667, 0.3412, 0.8039],\n",
      "         [0.8431, 0.7843, 0.8000,  ..., 0.7686, 0.7725, 0.8588]]])\n"
     ]
    }
   ],
   "source": [
    "# Build dataset\n",
    "\n",
    "# Transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "class myDataset(Dataset):\n",
    "\n",
    "    def __init__(self, path, transform=None):\n",
    "        \n",
    "        img_list = [\n",
    "            f.replace('.jpg', '') for f in listdir(path) \\\n",
    "            if f.endswith('.jpg') and isfile(join(path, f))\n",
    "        ]\n",
    "\n",
    "        self.len = len(img_list)\n",
    "        self.images = img_list\n",
    "        self.transform = transform\n",
    "        self.path = path\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        iid = self.images[index]\n",
    "        img = join(self.path, iid) + '.jpg'\n",
    "        img_pil = Image.open(img)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img_tensor = self.transform(img_pil)\n",
    "\n",
    "        return [img_tensor, iid]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    \n",
    "TestPath = Params['TestPath']\n",
    "# BatchSize = Params['BatchSize']\n",
    "BatchSize = 100\n",
    "    \n",
    "dataSet = myDataset(TestPath, transform=transform)\n",
    "dataLoader = DataLoader(dataSet, batch_size=BatchSize, shuffle=False)\n",
    "dataSize = len(dataSet)\n",
    "\n",
    "imgs, iids = next(iter(dataLoader))\n",
    "print('\\nImage shape:', imgs.shape)\n",
    "\n",
    "print('\\nImage ids')\n",
    "id_list = [''.join(iid) for iid in iids]\n",
    "print('  '+'\\n  '.join(id_list))\n",
    "\n",
    "img = imgs[0]\n",
    "print('\\nImage shape:', img.shape)\n",
    "\n",
    "print('\\nImage tensor:')\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Use GPU for train\n",
    "use_gpu = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_gpu else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model: /home/jovyan/models/dog-breed/resnet50_20240801-2306_acc88.pth\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=120, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Build Model \n",
    "# model = models.resnet50(pretrained=True)\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "\n",
    "# freeze all model parameters\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# New final layer with NumClasses\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, NumClasses)\n",
    "\n",
    "# load pretrained mode\n",
    "print('Load model:', Pretrain_abspath)\n",
    "model.load_state_dict(torch.load(Pretrain_abspath, weights_only=True))\n",
    "\n",
    "if use_gpu: model = model.cuda()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start testing...\n",
      "\n",
      "Probs:\n",
      "torch.Size([100, 120])\n",
      "tensor([[0.0087, 0.0067, 0.0100,  ..., 0.0079, 0.0093, 0.0066],\n",
      "        [0.0079, 0.0072, 0.0105,  ..., 0.0094, 0.0091, 0.0070],\n",
      "        [0.0046, 0.0083, 0.0077,  ..., 0.0045, 0.0054, 0.0067],\n",
      "        ...,\n",
      "        [0.0032, 0.0074, 0.0049,  ..., 0.0028, 0.0048, 0.0034],\n",
      "        [0.0116, 0.0175, 0.0076,  ..., 0.0175, 0.0181, 0.0056],\n",
      "        [0.0301, 0.0073, 0.0192,  ..., 0.0101, 0.0139, 0.0067]],\n",
      "       device='cuda:0')\n",
      "\n",
      "Preds:\n",
      "torch.Size([100])\n",
      "tensor([ 81, 110,   4,  47,   5,  42,  35,  11, 107,  60,   6,  72,  92,  14,\n",
      "        107,  87,   2, 111,  21,  69,  97,  48,  29,  97, 108,  59,  21, 103,\n",
      "         24,  87,  94,  25,  14,  39, 101,  89,   4,  96,  21,  28,  38,  81,\n",
      "         28,   5,  25,  57,  14,  64,  36,  52,  11,  36,   8, 105,  97,  36,\n",
      "         43,  89, 102,  54,  56,  34,  86,   3,   4,   2,  89,  61,  66,  43,\n",
      "         94,  41,  28,  21,  28,  13, 109,  83, 118,  99, 101,  10,  65,  17,\n",
      "         31,   4,  35,  21,  90,   5,  97,  39,  15,  67,  33,  67,   9,  94,\n",
      "         40, 114], device='cuda:0')\n",
      "\n",
      "0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, \n",
      "Testing time:   0.828470 minutes\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10357 entries, 0 to 10356\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   id          10357 non-null  object\n",
      " 1   prediction  10357 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 162.0+ KB\n",
      "None\n",
      "\n",
      "                                 id            prediction\n",
      "0  e458d6133dd1b436b047f86910f7fe34   irish_water_spaniel\n",
      "1  635e859fef2e4cfaf5546c4d0265c88e       tibetan_mastiff\n",
      "2  944ec36bc768ee309e51bf881dabcb15  bernese_mountain_dog\n",
      "3  616bf51988ee33e53d0e96c2367594fb                kelpie\n",
      "4  6c834ba0465f70e9abb2629864530b64              shih-tzu\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10357 entries, 0 to 10356\n",
      "Columns: 241 entries, id to 119\n",
      "dtypes: float64(120), object(121)\n",
      "memory usage: 19.0+ MB\n",
      "None\n",
      "\n",
      "    id scottish_deerhound maltese_dog afghan_hound entlebucher  \\\n",
      "0  NaN                NaN         NaN          NaN         NaN   \n",
      "1  NaN                NaN         NaN          NaN         NaN   \n",
      "2  NaN                NaN         NaN          NaN         NaN   \n",
      "3  NaN                NaN         NaN          NaN         NaN   \n",
      "4  NaN                NaN         NaN          NaN         NaN   \n",
      "\n",
      "  bernese_mountain_dog shih-tzu great_pyrenees pomeranian basenji  ...  \\\n",
      "0                  NaN      NaN            NaN        NaN     NaN  ...   \n",
      "1                  NaN      NaN            NaN        NaN     NaN  ...   \n",
      "2                  NaN      NaN            NaN        NaN     NaN  ...   \n",
      "3                  NaN      NaN            NaN        NaN     NaN  ...   \n",
      "4                  NaN      NaN            NaN        NaN     NaN  ...   \n",
      "\n",
      "        110       111       112       113       114       115       116  \\\n",
      "0  0.007558  0.006431  0.012503  0.004848  0.006724  0.006460  0.006884   \n",
      "1  0.075595  0.007298  0.005265  0.004825  0.017849  0.009598  0.005829   \n",
      "2  0.005017  0.004191  0.004089  0.006837  0.003289  0.005543  0.005862   \n",
      "3  0.005403  0.024843  0.004615  0.003490  0.002746  0.005473  0.008543   \n",
      "4  0.004983  0.004273  0.003949  0.003452  0.004596  0.005020  0.011581   \n",
      "\n",
      "        117       118       119  \n",
      "0  0.007934  0.009313  0.006573  \n",
      "1  0.009378  0.009094  0.006990  \n",
      "2  0.004475  0.005371  0.006718  \n",
      "3  0.003421  0.006332  0.005832  \n",
      "4  0.006018  0.009337  0.005891  \n",
      "\n",
      "[5 rows x 241 columns]\n"
     ]
    }
   ],
   "source": [
    "# Pediction\n",
    "import torch.nn.functional as nnf\n",
    "\n",
    "# Output submission\n",
    "# fname_submission = 'submission.csv'\n",
    "# f_abspath = join(OutPath, fname_submission)\n",
    "\n",
    "cols_preds = ['id', 'prediction']\n",
    "df_preds = pd.DataFrame(columns=cols_preds)\n",
    "\n",
    "cols_probs = ['id'] + selected_breeds\n",
    "df_probs = pd.DataFrame(columns=cols_probs)\n",
    "\n",
    "start_time = time.time()\n",
    "print('Start testing...')\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for i, (inputs, iids) in enumerate(dataLoader):\n",
    "\n",
    "    inputs = Variable(inputs.cuda())\n",
    "    iid_list = list(iids)\n",
    "    \n",
    "    # with torch.set_grad_enabled(True):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "        \n",
    "        if i == 0:\n",
    "            # print(); print(len(iid_list)); print('\\n'.join(iid_list))\n",
    "            print('\\nProbs:'); print(probs.shape); print(probs)\n",
    "            print('\\nPreds:'); print(preds.shape); print(preds)\n",
    "            print()\n",
    "    \n",
    "    pred_list = preds.tolist()\n",
    "    pred_breeds = [dict_bid_bw.get(x) for x in pred_list]\n",
    "    \n",
    "    df_tmp = pd.DataFrame({\n",
    "        'id': iid_list,\n",
    "        'prediction': pred_breeds\n",
    "    })\n",
    "    # df_preds = df_preds.append(df_tmp)\n",
    "    df_preds = pd.concat([df_preds, df_tmp], ignore_index=True)\n",
    "\n",
    "    df_tmp = pd.DataFrame({'id': iid_list})\n",
    "    \n",
    "    # df_tmp[selected_breeds] = pd.DataFrame(probs.tolist())\n",
    "    probs_df = pd.DataFrame(probs.tolist(), columns=selected_breeds)\n",
    "    df_tmp = pd.DataFrame(index=probs_df.index)\n",
    "    df_tmp = pd.concat([df_tmp, probs_df], axis=1, ignore_index=True)\n",
    "    df_tmp = df_tmp.copy()    \n",
    "\n",
    "    # df_probs = df_probs.append(df_tmp)\n",
    "    df_probs = pd.concat([df_probs, df_tmp], ignore_index=True)\n",
    "\n",
    "    print(i, end=', ')\n",
    "    \n",
    "print()\n",
    "print('Testing time: {:10f} minutes'.format((time.time()-start_time)/60))    \n",
    "\n",
    "print(); print(df_preds.info())\n",
    "print(); print(df_preds.head())\n",
    "\n",
    "print(); print(df_probs.info())\n",
    "print(); print(df_probs.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "currDT = datetime.now()\n",
    "currStr = currDT.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "fname = 'Prediction_{}.csv'.format(currStr)\n",
    "df_preds.to_csv(join(OutPath, fname), index=False)\n",
    "\n",
    "fname = 'Probability_{}.csv'.format(currStr)\n",
    "df_probs.to_csv(join(OutPath, fname), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
