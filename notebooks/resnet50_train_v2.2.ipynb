{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  2.4.0+cu121\n",
      "Torchvision Version:  0.19.0+cu121\n"
     ]
    }
   ],
   "source": [
    "# From: https://www.kaggle.com/c/dog-breed-identification/data\n",
    "# Author: Morpheus Hsieh (morpheus.hsieh@gmail.com)\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import os, sys\n",
    "import copy\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "from os import listdir\n",
    "from os.path import join, exists, isfile\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:\n",
      "{\n",
      "  'DataPath'    : '/home/jovyan/data/dog-breed/',\n",
      "  'OutPath'     : '/home/jovyan/output/dog-breed/',\n",
      "  'ProcPath'    : '/home/jovyan/output/dog-breed/',\n",
      "  'PreTrainPath': '/home/jovyan/models/dog-breed/',\n",
      "  'PreTrainFile': '',\n",
      "  'TestPath'    : '/home/jovyan/data/dog-breed/test',\n",
      "  'TrainPath'   : '/home/jovyan/data/dog-breed/train',\n",
      "  'CsvLabel'    : 'labels.csv',\n",
      "  'BatchSize'   : 16,\n",
      "  'FracForTrain': 0.8\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Params = {\n",
    "#     'DataPath'    : r'D:\\GitWork\\dog_breed\\data',\n",
    "#     'OutPath'     : r'D:\\GitWork\\dog_breed\\output',\n",
    "#     'ProcPath'    : r'D:\\GitWork\\dog_breed\\processed',\n",
    "#     'PreTrainPath': r'D:\\GitWork\\dog_breed\\pretrained',\n",
    "#     'PreTrainFile': '',\n",
    "#     'TestPath'    : r'D:\\Dataset\\dog-breed-identification\\test',\n",
    "#     'TrainPath'   : r'D:\\Dataset\\dog-breed-identification\\train',\n",
    "#     'CsvLabel'    : 'labels.csv',\n",
    "#     'BatchSize'   : 16,\n",
    "#     'FracForTrain': 0.8\n",
    "# }\n",
    "\n",
    "Params = {\n",
    "    'DataPath'    : r'/home/jovyan/data/dog-breed/',\n",
    "    'OutPath'     : r'/home/jovyan/output/dog-breed/',\n",
    "    'ProcPath'    : r'/home/jovyan/output/dog-breed/',\n",
    "    'PreTrainPath': r'/home/jovyan/models/dog-breed/',\n",
    "    'PreTrainFile': r'',\n",
    "    'TestPath'    : r'/home/jovyan/data/dog-breed/test/',\n",
    "    'TrainPath'   : r'/home/jovyan/data/dog-breed/train/',\n",
    "    'CsvLabel'    : 'labels.csv',\n",
    "    'BatchSize'   : 16,\n",
    "    'FracForTrain': 0.8\n",
    "}\n",
    "\n",
    "\n",
    "def prettyDict(dic, indent=2):\n",
    "    array = []\n",
    "    key_maxlen = 0\n",
    "    item_cnt = 0\n",
    "    item_size = len(dic)\n",
    "    split_str = ': '\n",
    "    \n",
    "    for key, val in dic.items():\n",
    "        if key_maxlen < len(str(key)): \n",
    "            key_maxlen = len(str(key))\n",
    "        \n",
    "        tmpstr = ''\n",
    "        tmpstr += f\"'{key}'\" if isinstance(key, str) else f\"{key}\"\n",
    "        tmpstr += split_str\n",
    "        tmpstr += f\"'{val}'\" if isinstance(val, str) else f\"{val}\"\n",
    "\n",
    "        item_cnt += 1\n",
    "        if item_cnt < item_size: tmpstr += ','\n",
    "        array.append(tmpstr)\n",
    "    \n",
    "    for i in range(len(array)):\n",
    "        inStr = array[i]\n",
    "        ary = inStr.split(split_str)\n",
    "        key = ary[0].ljust(key_maxlen+2)\n",
    "        val = ary[1]\n",
    "        array[i] = (' '*indent) + key + ': ' + val\n",
    "        \n",
    "    outstr = '{\\n' + '\\n'.join(array) + '\\n}'\n",
    "    return outstr\n",
    "\n",
    "outstr = prettyDict(Params)\n",
    "print('Parameters:')\n",
    "print(outstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10222 entries, 0 to 10221\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      10222 non-null  object\n",
      " 1   breed   10222 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 159.8+ KB\n",
      "None\n",
      "\n",
      "                                 id             breed\n",
      "0  000bec180eb18c7604dcecc8fe0dba07       boston_bull\n",
      "1  001513dfcb2ffafc82cccf4d8bbaba97             dingo\n",
      "2  001cdf01b096e06d78e9e5112d419397          pekinese\n",
      "3  00214f311d5d2247d5dfe4fe24b2303d          bluetick\n",
      "4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever\n"
     ]
    }
   ],
   "source": [
    "# Read breed information from csv\n",
    "DataPath = Params.get('DataPath')\n",
    "csv_labels = Params.get('CsvLabel')\n",
    "f_abspath = join(DataPath, csv_labels)\n",
    "\n",
    "df_labels = pd.read_csv(f_abspath)\n",
    "\n",
    "print(df_labels.info())\n",
    "print()\n",
    "print(df_labels.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n",
       "      <td>boston_bull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n",
       "      <td>dingo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001cdf01b096e06d78e9e5112d419397</td>\n",
       "      <td>pekinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00214f311d5d2247d5dfe4fe24b2303d</td>\n",
       "      <td>bluetick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n",
       "      <td>golden_retriever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>002211c81b498ef88e1b40b9abf84e1d</td>\n",
       "      <td>bedlington_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00290d3e1fdd27226ba27a8ce248ce85</td>\n",
       "      <td>bedlington_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>002a283a315af96eaea0e28e7163b21b</td>\n",
       "      <td>borzoi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>003df8b8a8b05244b1d920bb6cf451f9</td>\n",
       "      <td>basenji</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0042188c895a2f14ef64a918ed9c7b64</td>\n",
       "      <td>scottish_deerhound</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id               breed\n",
       "0  000bec180eb18c7604dcecc8fe0dba07         boston_bull\n",
       "1  001513dfcb2ffafc82cccf4d8bbaba97               dingo\n",
       "2  001cdf01b096e06d78e9e5112d419397            pekinese\n",
       "3  00214f311d5d2247d5dfe4fe24b2303d            bluetick\n",
       "4  0021f9ceb3235effd7fcde7f7538ed62    golden_retriever\n",
       "5  002211c81b498ef88e1b40b9abf84e1d  bedlington_terrier\n",
       "6  00290d3e1fdd27226ba27a8ce248ce85  bedlington_terrier\n",
       "7  002a283a315af96eaea0e28e7163b21b              borzoi\n",
       "8  003df8b8a8b05244b1d920bb6cf451f9             basenji\n",
       "9  0042188c895a2f14ef64a918ed9c7b64  scottish_deerhound"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "display(df_labels.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120 entries, 0 to 119\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   breed_id  120 non-null    int64 \n",
      " 1   breed     120 non-null    object\n",
      " 2   count     120 non-null    int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 2.9+ KB\n",
      "None\n",
      "\n",
      "   breed_id                 breed  count\n",
      "0         0    scottish_deerhound    126\n",
      "1         1           maltese_dog    117\n",
      "2         2          afghan_hound    116\n",
      "3         3           entlebucher    115\n",
      "4         4  bernese_mountain_dog    114\n",
      "\n",
      "Num classes: 120\n"
     ]
    }
   ],
   "source": [
    "# Count all breeds\n",
    "def countBreeds(df):\n",
    "    df1 = df_labels.groupby(\"breed\")[\"id\"].count().reset_index(name=\"count\")\n",
    "    df1 = df1.sort_values(by='count', ascending=False).reset_index(drop=True)\n",
    "    df1.insert(0, 'breed_id', df1.index)\n",
    "    return df1\n",
    "\n",
    "df_breeds = countBreeds(df_labels)\n",
    "print(df_breeds.info())\n",
    "print()\n",
    "print(df_breeds.head())\n",
    "\n",
    "NumClasses = int(df_breeds.shape[0])\n",
    "print('\\nNum classes:', NumClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10222 entries, 0 to 10221\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   image     10222 non-null  object\n",
      " 1   breed_id  10222 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 159.8+ KB\n",
      "None\n",
      "                                               image  breed_id\n",
      "0  /home/jovyan/data/dog-breed/train/000bec180eb1...        42\n",
      "1  /home/jovyan/data/dog-breed/train/001513dfcb2f...        72\n",
      "2  /home/jovyan/data/dog-breed/train/001cdf01b096...        94\n",
      "3  /home/jovyan/data/dog-breed/train/00214f311d5d...        50\n",
      "4  /home/jovyan/data/dog-breed/train/0021f9ceb323...       115\n"
     ]
    }
   ],
   "source": [
    "# Process labels\n",
    "\n",
    "dict_bid_fw = dict(df_breeds[['breed', 'breed_id']].values)\n",
    "# print(dict_bid_fw)\n",
    "\n",
    "dict_bid_bw = dict(df_breeds[['breed_id', 'breed']].values)\n",
    "# print(dict_bid_bw)\n",
    "\n",
    "# Build processed labels file\n",
    "df_data = pd.DataFrame(columns=['image', 'breed_id'])\n",
    "df_data['breed_id'] = df_labels.breed.map(dict_bid_fw)\n",
    "\n",
    "TranPath = Params['TrainPath']\n",
    "\n",
    "df_data['image'] = df_labels.apply (\n",
    "    lambda row: join(TranPath, row['id']+'.jpg') \\\n",
    "    if exists(join(TranPath, row['id']+'.jpg')) else None, \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(df_data.info())\n",
    "print(df_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSet size: {'train': 8177, 'valid': 2045}\n",
      "\n",
      "Image shape: torch.Size([16, 3, 224, 224])\n",
      "Label shape: torch.Size([16])\n",
      "\n",
      "Image iid:\n",
      "  d65bc49d1cf6be1fe8fd5798c4a28e08\n",
      "  3d048af542545494b12fd46c06bc5a52\n",
      "  68fe92544e3c171703144e0df84c964d\n",
      "  b2004690624be6cb621bd557815e7638\n",
      "  63021bfb22038c0e4095ada8cf691b76\n",
      "  bddd13e14c54a5ca227fddcf968d99c3\n",
      "  05719b998e57a11b863a322ecc7652a5\n",
      "  07a0214fa84969b5256bf7d20f1b3a9b\n",
      "  3efa1c5b966b6ce836b87db21f00c48b\n",
      "  be390f190d4ab118992e2784b8522d50\n",
      "  c36626ef165cd73783a2e760aaa2fc72\n",
      "  42d2ca5eb80634db250e8b2db9f13b08\n",
      "  d9f0ac78472ce66dd48364521d396835\n",
      "  fc2049d582b3444ed99af4a5c13b49e5\n",
      "  d8488f933f021216d7a39f6e8f1bc9c5\n",
      "  bcf3f1b3f1424edece51c1275a226fd4\n",
      "\n",
      "Image shape: torch.Size([3, 224, 224])\n",
      "\n",
      "tensor([[[-1.0733, -0.5767,  0.3994,  ..., -1.4329, -1.4843, -1.5528],\n",
      "         [-1.1075, -0.6109,  0.4337,  ..., -1.3815, -1.3987, -1.3644],\n",
      "         [-1.1418, -0.6109,  0.4166,  ..., -1.4158, -1.3130, -1.2959],\n",
      "         ...,\n",
      "         [-0.8678, -0.8849, -0.8849,  ..., -0.8849, -0.8849, -0.8849],\n",
      "         [-0.8678, -0.8507, -0.8678,  ..., -0.8849, -0.9192, -0.9363],\n",
      "         [-0.8335, -0.8678, -0.8507,  ..., -0.9363, -0.9363, -0.9877]],\n",
      "\n",
      "        [[-1.1078, -0.7227,  0.3277,  ..., -1.3880, -1.3704, -1.4405],\n",
      "         [-1.1429, -0.7752,  0.3102,  ..., -1.3354, -1.2829, -1.2479],\n",
      "         [-1.1429, -0.7752,  0.2752,  ..., -1.3529, -1.2129, -1.1779],\n",
      "         ...,\n",
      "         [-0.8277, -0.8803, -0.8803,  ..., -0.8102, -0.8627, -0.8627],\n",
      "         [-0.8277, -0.8452, -0.8803,  ..., -0.8102, -0.8277, -0.8452],\n",
      "         [-0.8102, -0.8452, -0.8803,  ..., -0.8452, -0.8627, -0.8803]],\n",
      "\n",
      "        [[-0.9156, -0.6541,  0.2522,  ..., -0.9853, -1.0724, -1.1247],\n",
      "         [-0.9504, -0.7064,  0.2522,  ..., -0.8981, -0.9678, -0.9330],\n",
      "         [-0.9504, -0.6715,  0.2348,  ..., -1.0201, -0.8807, -0.8458],\n",
      "         ...,\n",
      "         [-0.6541, -0.6367, -0.6541,  ..., -0.5495, -0.5670, -0.5670],\n",
      "         [-0.6541, -0.6018, -0.6367,  ..., -0.6193, -0.5844, -0.5670],\n",
      "         [-0.5670, -0.5844, -0.6541,  ..., -0.6367, -0.6193, -0.5844]]])\n",
      "\n",
      "Labels: tensor(35)\n"
     ]
    }
   ],
   "source": [
    "# Create dataset\n",
    "\n",
    "# Transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean = [0.485, 0.456, 0.406],\n",
    "        std  = [0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "class myDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df, phase='train', frac=0.8, transform=None):\n",
    "        \n",
    "        num_rows = df.shape[0]\n",
    "        train_len = int(float(frac) * float(num_rows))\n",
    "        valid_len = num_rows - train_len\n",
    "        \n",
    "        # data = df.head(train_len) if phase=='train' else df.tail(valid_len)\n",
    "        \n",
    "        # get random image id without duplicates\n",
    "        idx_ary = np.arange(len(df))\n",
    "        idx_ary_rand = np.random.permutation(idx_ary) # random shuffle\n",
    "        \n",
    "        data_len = train_len if phase=='train' else valid_len\n",
    "        data = df.loc[idx_ary_rand[:data_len]]\n",
    "        \n",
    "        self.images = data['image'].tolist()\n",
    "        self.labels = data['breed_id'].tolist()\n",
    "\n",
    "        self.transform = transform\n",
    "        self.len = len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        f_abspath = self.images[index]\n",
    "        img_pil = Image.open(f_abspath)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img_pil)\n",
    "\n",
    "        lbl = int(self.labels[index])\n",
    "        iid = os.path.split(f_abspath)[1].replace('.jpg', '')\n",
    "        \n",
    "        return [img, lbl, iid]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "\n",
    "frac = Params['FracForTrain']\n",
    "\n",
    "phases = ['train', 'valid']\n",
    "dataSet = { \n",
    "    x: myDataset(df_data, phase=x, frac=frac, transform=transform) for x in phases \n",
    "}\n",
    "\n",
    "BatchSize = Params['BatchSize']\n",
    "dataLoader = {\n",
    "    x: DataLoader(dataSet[x], batch_size=BatchSize, shuffle=True) for x in phases\n",
    "}\n",
    "\n",
    "dataSizes = { x: len(dataSet[x]) for x in phases }\n",
    "print('DataSet size:', dataSizes)\n",
    "\n",
    "trainLoader = dataLoader['train']\n",
    "imgs, lbls, iids = next(iter(trainLoader))\n",
    "print('\\nImage shape:', imgs.size())\n",
    "print('Label shape:', lbls.size())\n",
    "\n",
    "print('\\nImage iid:')\n",
    "id_list = [''.join(iid) for iid in iids]\n",
    "print('  '+'\\n  '.join(id_list))\n",
    "\n",
    "img = imgs[0]\n",
    "print('\\nImage shape:', img.shape)\n",
    "print(); print(img)\n",
    "\n",
    "print('\\nLabels:', lbls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_gpu:  True\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Use GPU for train\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print(\"use_gpu: \", use_gpu)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if use_gpu else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=120, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Build Model\n",
    "def buildModel(use_gpu, numClasses, preTrainModel=None):\n",
    "    # model = models.resnet50(pretrained=True)\n",
    "    # model = torchvision.models.resnet50()\n",
    "    model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "\n",
    "    # freeze all model parameters\n",
    "    for param in model.parameters():\n",
    "        model.requires_grad = False\n",
    "\n",
    "    # new final layer with 16 classes\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, numClasses)\n",
    "    \n",
    "    if preTrainModel is not None:\n",
    "        model.load_state_dict(preTrainModel)\n",
    "        \n",
    "    if use_gpu: \n",
    "        model = model.cuda()\n",
    "        \n",
    "    return model\n",
    "\n",
    "\n",
    "TrainPath = Params['PreTrainPath']\n",
    "TrainFile = Params['PreTrainFile']\n",
    "f_pretrain = join(TrainPath, TrainFile)\n",
    "\n",
    "pretrain_model = None\n",
    "if exists(f_pretrain) and isfile(f_pretrain):\n",
    "    pretrain_model = torch.load(join(path, fname), weights_only=True)\n",
    "\n",
    "model = buildModel(use_gpu, NumClasses, preTrainModel=pretrain_model)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "conv1.weight \t torch.Size([64, 3, 7, 7])\n",
      "bn1.weight \t torch.Size([64])\n",
      "bn1.bias \t torch.Size([64])\n",
      "bn1.running_mean \t torch.Size([64])\n",
      "bn1.running_var \t torch.Size([64])\n",
      "bn1.num_batches_tracked \t torch.Size([])\n",
      "layer1.0.conv1.weight \t torch.Size([64, 64, 1, 1])\n",
      "layer1.0.bn1.weight \t torch.Size([64])\n",
      "layer1.0.bn1.bias \t torch.Size([64])\n",
      "layer1.0.bn1.running_mean \t torch.Size([64])\n",
      "layer1.0.bn1.running_var \t torch.Size([64])\n",
      "layer1.0.bn1.num_batches_tracked \t torch.Size([])\n",
      "layer1.0.conv2.weight \t torch.Size([64, 64, 3, 3])\n",
      "layer1.0.bn2.weight \t torch.Size([64])\n",
      "layer1.0.bn2.bias \t torch.Size([64])\n",
      "layer1.0.bn2.running_mean \t torch.Size([64])\n",
      "layer1.0.bn2.running_var \t torch.Size([64])\n",
      "layer1.0.bn2.num_batches_tracked \t torch.Size([])\n",
      "layer1.0.conv3.weight \t torch.Size([256, 64, 1, 1])\n",
      "layer1.0.bn3.weight \t torch.Size([256])\n",
      "layer1.0.bn3.bias \t torch.Size([256])\n",
      "layer1.0.bn3.running_mean \t torch.Size([256])\n",
      "layer1.0.bn3.running_var \t torch.Size([256])\n",
      "layer1.0.bn3.num_batches_tracked \t torch.Size([])\n",
      "layer1.0.downsample.0.weight \t torch.Size([256, 64, 1, 1])\n",
      "layer1.0.downsample.1.weight \t torch.Size([256])\n",
      "layer1.0.downsample.1.bias \t torch.Size([256])\n",
      "layer1.0.downsample.1.running_mean \t torch.Size([256])\n",
      "layer1.0.downsample.1.running_var \t torch.Size([256])\n",
      "layer1.0.downsample.1.num_batches_tracked \t torch.Size([])\n",
      "layer1.1.conv1.weight \t torch.Size([64, 256, 1, 1])\n",
      "layer1.1.bn1.weight \t torch.Size([64])\n",
      "layer1.1.bn1.bias \t torch.Size([64])\n",
      "layer1.1.bn1.running_mean \t torch.Size([64])\n",
      "layer1.1.bn1.running_var \t torch.Size([64])\n",
      "layer1.1.bn1.num_batches_tracked \t torch.Size([])\n",
      "layer1.1.conv2.weight \t torch.Size([64, 64, 3, 3])\n",
      "layer1.1.bn2.weight \t torch.Size([64])\n",
      "layer1.1.bn2.bias \t torch.Size([64])\n",
      "layer1.1.bn2.running_mean \t torch.Size([64])\n",
      "layer1.1.bn2.running_var \t torch.Size([64])\n",
      "layer1.1.bn2.num_batches_tracked \t torch.Size([])\n",
      "layer1.1.conv3.weight \t torch.Size([256, 64, 1, 1])\n",
      "layer1.1.bn3.weight \t torch.Size([256])\n",
      "layer1.1.bn3.bias \t torch.Size([256])\n",
      "layer1.1.bn3.running_mean \t torch.Size([256])\n",
      "layer1.1.bn3.running_var \t torch.Size([256])\n",
      "layer1.1.bn3.num_batches_tracked \t torch.Size([])\n",
      "layer1.2.conv1.weight \t torch.Size([64, 256, 1, 1])\n",
      "layer1.2.bn1.weight \t torch.Size([64])\n",
      "layer1.2.bn1.bias \t torch.Size([64])\n",
      "layer1.2.bn1.running_mean \t torch.Size([64])\n",
      "layer1.2.bn1.running_var \t torch.Size([64])\n",
      "layer1.2.bn1.num_batches_tracked \t torch.Size([])\n",
      "layer1.2.conv2.weight \t torch.Size([64, 64, 3, 3])\n",
      "layer1.2.bn2.weight \t torch.Size([64])\n",
      "layer1.2.bn2.bias \t torch.Size([64])\n",
      "layer1.2.bn2.running_mean \t torch.Size([64])\n",
      "layer1.2.bn2.running_var \t torch.Size([64])\n",
      "layer1.2.bn2.num_batches_tracked \t torch.Size([])\n",
      "layer1.2.conv3.weight \t torch.Size([256, 64, 1, 1])\n",
      "layer1.2.bn3.weight \t torch.Size([256])\n",
      "layer1.2.bn3.bias \t torch.Size([256])\n",
      "layer1.2.bn3.running_mean \t torch.Size([256])\n",
      "layer1.2.bn3.running_var \t torch.Size([256])\n",
      "layer1.2.bn3.num_batches_tracked \t torch.Size([])\n",
      "layer2.0.conv1.weight \t torch.Size([128, 256, 1, 1])\n",
      "layer2.0.bn1.weight \t torch.Size([128])\n",
      "layer2.0.bn1.bias \t torch.Size([128])\n",
      "layer2.0.bn1.running_mean \t torch.Size([128])\n",
      "layer2.0.bn1.running_var \t torch.Size([128])\n",
      "layer2.0.bn1.num_batches_tracked \t torch.Size([])\n",
      "layer2.0.conv2.weight \t torch.Size([128, 128, 3, 3])\n",
      "layer2.0.bn2.weight \t torch.Size([128])\n",
      "layer2.0.bn2.bias \t torch.Size([128])\n",
      "layer2.0.bn2.running_mean \t torch.Size([128])\n",
      "layer2.0.bn2.running_var \t torch.Size([128])\n",
      "layer2.0.bn2.num_batches_tracked \t torch.Size([])\n",
      "layer2.0.conv3.weight \t torch.Size([512, 128, 1, 1])\n",
      "layer2.0.bn3.weight \t torch.Size([512])\n",
      "layer2.0.bn3.bias \t torch.Size([512])\n",
      "layer2.0.bn3.running_mean \t torch.Size([512])\n",
      "layer2.0.bn3.running_var \t torch.Size([512])\n",
      "layer2.0.bn3.num_batches_tracked \t torch.Size([])\n",
      "layer2.0.downsample.0.weight \t torch.Size([512, 256, 1, 1])\n",
      "layer2.0.downsample.1.weight \t torch.Size([512])\n",
      "layer2.0.downsample.1.bias \t torch.Size([512])\n",
      "layer2.0.downsample.1.running_mean \t torch.Size([512])\n",
      "layer2.0.downsample.1.running_var \t torch.Size([512])\n",
      "layer2.0.downsample.1.num_batches_tracked \t torch.Size([])\n",
      "layer2.1.conv1.weight \t torch.Size([128, 512, 1, 1])\n",
      "layer2.1.bn1.weight \t torch.Size([128])\n",
      "layer2.1.bn1.bias \t torch.Size([128])\n",
      "layer2.1.bn1.running_mean \t torch.Size([128])\n",
      "layer2.1.bn1.running_var \t torch.Size([128])\n",
      "layer2.1.bn1.num_batches_tracked \t torch.Size([])\n",
      "layer2.1.conv2.weight \t torch.Size([128, 128, 3, 3])\n",
      "layer2.1.bn2.weight \t torch.Size([128])\n",
      "layer2.1.bn2.bias \t torch.Size([128])\n",
      "layer2.1.bn2.running_mean \t torch.Size([128])\n",
      "layer2.1.bn2.running_var \t torch.Size([128])\n",
      "layer2.1.bn2.num_batches_tracked \t torch.Size([])\n",
      "layer2.1.conv3.weight \t torch.Size([512, 128, 1, 1])\n",
      "layer2.1.bn3.weight \t torch.Size([512])\n",
      "layer2.1.bn3.bias \t torch.Size([512])\n",
      "layer2.1.bn3.running_mean \t torch.Size([512])\n",
      "layer2.1.bn3.running_var \t torch.Size([512])\n",
      "layer2.1.bn3.num_batches_tracked \t torch.Size([])\n",
      "layer2.2.conv1.weight \t torch.Size([128, 512, 1, 1])\n",
      "layer2.2.bn1.weight \t torch.Size([128])\n",
      "layer2.2.bn1.bias \t torch.Size([128])\n",
      "layer2.2.bn1.running_mean \t torch.Size([128])\n",
      "layer2.2.bn1.running_var \t torch.Size([128])\n",
      "layer2.2.bn1.num_batches_tracked \t torch.Size([])\n",
      "layer2.2.conv2.weight \t torch.Size([128, 128, 3, 3])\n",
      "layer2.2.bn2.weight \t torch.Size([128])\n",
      "layer2.2.bn2.bias \t torch.Size([128])\n",
      "layer2.2.bn2.running_mean \t torch.Size([128])\n",
      "layer2.2.bn2.running_var \t torch.Size([128])\n",
      "layer2.2.bn2.num_batches_tracked \t torch.Size([])\n",
      "layer2.2.conv3.weight \t torch.Size([512, 128, 1, 1])\n",
      "layer2.2.bn3.weight \t torch.Size([512])\n",
      "layer2.2.bn3.bias \t torch.Size([512])\n",
      "layer2.2.bn3.running_mean \t torch.Size([512])\n",
      "layer2.2.bn3.running_var \t torch.Size([512])\n",
      "layer2.2.bn3.num_batches_tracked \t torch.Size([])\n",
      "layer2.3.conv1.weight \t torch.Size([128, 512, 1, 1])\n",
      "layer2.3.bn1.weight \t torch.Size([128])\n",
      "layer2.3.bn1.bias \t torch.Size([128])\n",
      "layer2.3.bn1.running_mean \t torch.Size([128])\n",
      "layer2.3.bn1.running_var \t torch.Size([128])\n",
      "layer2.3.bn1.num_batches_tracked \t torch.Size([])\n",
      "layer2.3.conv2.weight \t torch.Size([128, 128, 3, 3])\n",
      "layer2.3.bn2.weight \t torch.Size([128])\n",
      "layer2.3.bn2.bias \t torch.Size([128])\n",
      "layer2.3.bn2.running_mean \t torch.Size([128])\n",
      "layer2.3.bn2.running_var \t torch.Size([128])\n",
      "layer2.3.bn2.num_batches_tracked \t torch.Size([])\n",
      "layer2.3.conv3.weight \t torch.Size([512, 128, 1, 1])\n",
      "layer2.3.bn3.weight \t torch.Size([512])\n",
      "layer2.3.bn3.bias \t torch.Size([512])\n",
      "layer2.3.bn3.running_mean \t torch.Size([512])\n",
      "layer2.3.bn3.running_var \t torch.Size([512])\n",
      "layer2.3.bn3.num_batches_tracked \t torch.Size([])\n",
      "layer3.0.conv1.weight \t torch.Size([256, 512, 1, 1])\n",
      "layer3.0.bn1.weight \t torch.Size([256])\n",
      "layer3.0.bn1.bias \t torch.Size([256])\n",
      "layer3.0.bn1.running_mean \t torch.Size([256])\n",
      "layer3.0.bn1.running_var \t torch.Size([256])\n",
      "layer3.0.bn1.num_batches_tracked \t torch.Size([])\n",
      "layer3.0.conv2.weight \t torch.Size([256, 256, 3, 3])\n",
      "layer3.0.bn2.weight \t torch.Size([256])\n",
      "layer3.0.bn2.bias \t torch.Size([256])\n",
      "layer3.0.bn2.running_mean \t torch.Size([256])\n",
      "layer3.0.bn2.running_var \t torch.Size([256])\n",
      "layer3.0.bn2.num_batches_tracked \t torch.Size([])\n",
      "layer3.0.conv3.weight \t torch.Size([1024, 256, 1, 1])\n",
      "layer3.0.bn3.weight \t torch.Size([1024])\n",
      "layer3.0.bn3.bias \t torch.Size([1024])\n",
      "layer3.0.bn3.running_mean \t torch.Size([1024])\n",
      "layer3.0.bn3.running_var \t torch.Size([1024])\n",
      "layer3.0.bn3.num_batches_tracked \t torch.Size([])\n",
      "layer3.0.downsample.0.weight \t torch.Size([1024, 512, 1, 1])\n",
      "layer3.0.downsample.1.weight \t torch.Size([1024])\n",
      "layer3.0.downsample.1.bias \t torch.Size([1024])\n",
      "layer3.0.downsample.1.running_mean \t torch.Size([1024])\n",
      "layer3.0.downsample.1.running_var \t torch.Size([1024])\n",
      "layer3.0.downsample.1.num_batches_tracked \t torch.Size([])\n",
      "layer3.1.conv1.weight \t torch.Size([256, 1024, 1, 1])\n",
      "layer3.1.bn1.weight \t torch.Size([256])\n",
      "layer3.1.bn1.bias \t torch.Size([256])\n",
      "layer3.1.bn1.running_mean \t torch.Size([256])\n",
      "layer3.1.bn1.running_var \t torch.Size([256])\n",
      "layer3.1.bn1.num_batches_tracked \t torch.Size([])\n",
      "layer3.1.conv2.weight \t torch.Size([256, 256, 3, 3])\n",
      "layer3.1.bn2.weight \t torch.Size([256])\n",
      "layer3.1.bn2.bias \t torch.Size([256])\n",
      "layer3.1.bn2.running_mean \t torch.Size([256])\n",
      "layer3.1.bn2.running_var \t torch.Size([256])\n",
      "layer3.1.bn2.num_batches_tracked \t torch.Size([])\n",
      "layer3.1.conv3.weight \t torch.Size([1024, 256, 1, 1])\n",
      "layer3.1.bn3.weight \t torch.Size([1024])\n",
      "layer3.1.bn3.bias \t torch.Size([1024])\n",
      "layer3.1.bn3.running_mean \t torch.Size([1024])\n",
      "layer3.1.bn3.running_var \t torch.Size([1024])\n",
      "layer3.1.bn3.num_batches_tracked \t torch.Size([])\n",
      "layer3.2.conv1.weight \t torch.Size([256, 1024, 1, 1])\n",
      "layer3.2.bn1.weight \t torch.Size([256])\n",
      "layer3.2.bn1.bias \t torch.Size([256])\n",
      "layer3.2.bn1.running_mean \t torch.Size([256])\n",
      "layer3.2.bn1.running_var \t torch.Size([256])\n",
      "layer3.2.bn1.num_batches_tracked \t torch.Size([])\n",
      "layer3.2.conv2.weight \t torch.Size([256, 256, 3, 3])\n",
      "layer3.2.bn2.weight \t torch.Size([256])\n",
      "layer3.2.bn2.bias \t torch.Size([256])\n",
      "layer3.2.bn2.running_mean \t torch.Size([256])\n",
      "layer3.2.bn2.running_var \t torch.Size([256])\n",
      "layer3.2.bn2.num_batches_tracked \t torch.Size([])\n",
      "layer3.2.conv3.weight \t torch.Size([1024, 256, 1, 1])\n",
      "layer3.2.bn3.weight \t torch.Size([1024])\n",
      "layer3.2.bn3.bias \t torch.Size([1024])\n",
      "layer3.2.bn3.running_mean \t torch.Size([1024])\n",
      "layer3.2.bn3.running_var \t torch.Size([1024])\n",
      "layer3.2.bn3.num_batches_tracked \t torch.Size([])\n",
      "layer3.3.conv1.weight \t torch.Size([256, 1024, 1, 1])\n",
      "layer3.3.bn1.weight \t torch.Size([256])\n",
      "layer3.3.bn1.bias \t torch.Size([256])\n",
      "layer3.3.bn1.running_mean \t torch.Size([256])\n",
      "layer3.3.bn1.running_var \t torch.Size([256])\n",
      "layer3.3.bn1.num_batches_tracked \t torch.Size([])\n",
      "layer3.3.conv2.weight \t torch.Size([256, 256, 3, 3])\n",
      "layer3.3.bn2.weight \t torch.Size([256])\n",
      "layer3.3.bn2.bias \t torch.Size([256])\n",
      "layer3.3.bn2.running_mean \t torch.Size([256])\n",
      "layer3.3.bn2.running_var \t torch.Size([256])\n",
      "layer3.3.bn2.num_batches_tracked \t torch.Size([])\n",
      "layer3.3.conv3.weight \t torch.Size([1024, 256, 1, 1])\n",
      "layer3.3.bn3.weight \t torch.Size([1024])\n",
      "layer3.3.bn3.bias \t torch.Size([1024])\n",
      "layer3.3.bn3.running_mean \t torch.Size([1024])\n",
      "layer3.3.bn3.running_var \t torch.Size([1024])\n",
      "layer3.3.bn3.num_batches_tracked \t torch.Size([])\n",
      "layer3.4.conv1.weight \t torch.Size([256, 1024, 1, 1])\n",
      "layer3.4.bn1.weight \t torch.Size([256])\n",
      "layer3.4.bn1.bias \t torch.Size([256])\n",
      "layer3.4.bn1.running_mean \t torch.Size([256])\n",
      "layer3.4.bn1.running_var \t torch.Size([256])\n",
      "layer3.4.bn1.num_batches_tracked \t torch.Size([])\n",
      "layer3.4.conv2.weight \t torch.Size([256, 256, 3, 3])\n",
      "layer3.4.bn2.weight \t torch.Size([256])\n",
      "layer3.4.bn2.bias \t torch.Size([256])\n",
      "layer3.4.bn2.running_mean \t torch.Size([256])\n",
      "layer3.4.bn2.running_var \t torch.Size([256])\n",
      "layer3.4.bn2.num_batches_tracked \t torch.Size([])\n",
      "layer3.4.conv3.weight \t torch.Size([1024, 256, 1, 1])\n",
      "layer3.4.bn3.weight \t torch.Size([1024])\n",
      "layer3.4.bn3.bias \t torch.Size([1024])\n",
      "layer3.4.bn3.running_mean \t torch.Size([1024])\n",
      "layer3.4.bn3.running_var \t torch.Size([1024])\n",
      "layer3.4.bn3.num_batches_tracked \t torch.Size([])\n",
      "layer3.5.conv1.weight \t torch.Size([256, 1024, 1, 1])\n",
      "layer3.5.bn1.weight \t torch.Size([256])\n",
      "layer3.5.bn1.bias \t torch.Size([256])\n",
      "layer3.5.bn1.running_mean \t torch.Size([256])\n",
      "layer3.5.bn1.running_var \t torch.Size([256])\n",
      "layer3.5.bn1.num_batches_tracked \t torch.Size([])\n",
      "layer3.5.conv2.weight \t torch.Size([256, 256, 3, 3])\n",
      "layer3.5.bn2.weight \t torch.Size([256])\n",
      "layer3.5.bn2.bias \t torch.Size([256])\n",
      "layer3.5.bn2.running_mean \t torch.Size([256])\n",
      "layer3.5.bn2.running_var \t torch.Size([256])\n",
      "layer3.5.bn2.num_batches_tracked \t torch.Size([])\n",
      "layer3.5.conv3.weight \t torch.Size([1024, 256, 1, 1])\n",
      "layer3.5.bn3.weight \t torch.Size([1024])\n",
      "layer3.5.bn3.bias \t torch.Size([1024])\n",
      "layer3.5.bn3.running_mean \t torch.Size([1024])\n",
      "layer3.5.bn3.running_var \t torch.Size([1024])\n",
      "layer3.5.bn3.num_batches_tracked \t torch.Size([])\n",
      "layer4.0.conv1.weight \t torch.Size([512, 1024, 1, 1])\n",
      "layer4.0.bn1.weight \t torch.Size([512])\n",
      "layer4.0.bn1.bias \t torch.Size([512])\n",
      "layer4.0.bn1.running_mean \t torch.Size([512])\n",
      "layer4.0.bn1.running_var \t torch.Size([512])\n",
      "layer4.0.bn1.num_batches_tracked \t torch.Size([])\n",
      "layer4.0.conv2.weight \t torch.Size([512, 512, 3, 3])\n",
      "layer4.0.bn2.weight \t torch.Size([512])\n",
      "layer4.0.bn2.bias \t torch.Size([512])\n",
      "layer4.0.bn2.running_mean \t torch.Size([512])\n",
      "layer4.0.bn2.running_var \t torch.Size([512])\n",
      "layer4.0.bn2.num_batches_tracked \t torch.Size([])\n",
      "layer4.0.conv3.weight \t torch.Size([2048, 512, 1, 1])\n",
      "layer4.0.bn3.weight \t torch.Size([2048])\n",
      "layer4.0.bn3.bias \t torch.Size([2048])\n",
      "layer4.0.bn3.running_mean \t torch.Size([2048])\n",
      "layer4.0.bn3.running_var \t torch.Size([2048])\n",
      "layer4.0.bn3.num_batches_tracked \t torch.Size([])\n",
      "layer4.0.downsample.0.weight \t torch.Size([2048, 1024, 1, 1])\n",
      "layer4.0.downsample.1.weight \t torch.Size([2048])\n",
      "layer4.0.downsample.1.bias \t torch.Size([2048])\n",
      "layer4.0.downsample.1.running_mean \t torch.Size([2048])\n",
      "layer4.0.downsample.1.running_var \t torch.Size([2048])\n",
      "layer4.0.downsample.1.num_batches_tracked \t torch.Size([])\n",
      "layer4.1.conv1.weight \t torch.Size([512, 2048, 1, 1])\n",
      "layer4.1.bn1.weight \t torch.Size([512])\n",
      "layer4.1.bn1.bias \t torch.Size([512])\n",
      "layer4.1.bn1.running_mean \t torch.Size([512])\n",
      "layer4.1.bn1.running_var \t torch.Size([512])\n",
      "layer4.1.bn1.num_batches_tracked \t torch.Size([])\n",
      "layer4.1.conv2.weight \t torch.Size([512, 512, 3, 3])\n",
      "layer4.1.bn2.weight \t torch.Size([512])\n",
      "layer4.1.bn2.bias \t torch.Size([512])\n",
      "layer4.1.bn2.running_mean \t torch.Size([512])\n",
      "layer4.1.bn2.running_var \t torch.Size([512])\n",
      "layer4.1.bn2.num_batches_tracked \t torch.Size([])\n",
      "layer4.1.conv3.weight \t torch.Size([2048, 512, 1, 1])\n",
      "layer4.1.bn3.weight \t torch.Size([2048])\n",
      "layer4.1.bn3.bias \t torch.Size([2048])\n",
      "layer4.1.bn3.running_mean \t torch.Size([2048])\n",
      "layer4.1.bn3.running_var \t torch.Size([2048])\n",
      "layer4.1.bn3.num_batches_tracked \t torch.Size([])\n",
      "layer4.2.conv1.weight \t torch.Size([512, 2048, 1, 1])\n",
      "layer4.2.bn1.weight \t torch.Size([512])\n",
      "layer4.2.bn1.bias \t torch.Size([512])\n",
      "layer4.2.bn1.running_mean \t torch.Size([512])\n",
      "layer4.2.bn1.running_var \t torch.Size([512])\n",
      "layer4.2.bn1.num_batches_tracked \t torch.Size([])\n",
      "layer4.2.conv2.weight \t torch.Size([512, 512, 3, 3])\n",
      "layer4.2.bn2.weight \t torch.Size([512])\n",
      "layer4.2.bn2.bias \t torch.Size([512])\n",
      "layer4.2.bn2.running_mean \t torch.Size([512])\n",
      "layer4.2.bn2.running_var \t torch.Size([512])\n",
      "layer4.2.bn2.num_batches_tracked \t torch.Size([])\n",
      "layer4.2.conv3.weight \t torch.Size([2048, 512, 1, 1])\n",
      "layer4.2.bn3.weight \t torch.Size([2048])\n",
      "layer4.2.bn3.bias \t torch.Size([2048])\n",
      "layer4.2.bn3.running_mean \t torch.Size([2048])\n",
      "layer4.2.bn3.running_var \t torch.Size([2048])\n",
      "layer4.2.bn3.num_batches_tracked \t torch.Size([])\n",
      "fc.weight \t torch.Size([120, 2048])\n",
      "fc.bias \t torch.Size([120])\n"
     ]
    }
   ],
   "source": [
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer's state_dict:\n",
      "state \t {}\n",
      "param_groups \t [{'lr': 0.001, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'fused': None, 'initial_lr': 0.001, 'params': [0, 1]}]\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and validate Model\n",
    "\n",
    "def train_model(loader, model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "    \n",
    "    use_gpu = torch.cuda.is_available()\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    history  = {\n",
    "        'train_acc': [],\n",
    "        'train_los': [],\n",
    "        'valid_acc': [],\n",
    "        'valid_los': []\n",
    "    }\n",
    "    \n",
    "    dataset_sizes = {\n",
    "        'train': len(loader['train'].dataset),\n",
    "        'valid': len(loader['valid'].dataset)\n",
    "    }\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        for phase in ['train', 'valid']:\n",
    "            \n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0.0\n",
    "            \n",
    "            for inputs, labels, iids in loader[phase]:\n",
    "                if use_gpu:\n",
    "                    inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs.data, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                \n",
    "                # statistic\n",
    "                running_loss += loss.item()\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "            \n",
    "            data_size = dataset_sizes[phase]\n",
    "            \n",
    "            if phase == 'train':\n",
    "                train_epoch_loss = running_loss / data_size\n",
    "                train_epoch_acc  = running_corrects / data_size\n",
    "            else:\n",
    "                valid_epoch_loss = running_loss / data_size\n",
    "                valid_epoch_acc  = running_corrects / data_size\n",
    "\n",
    "            if phase == 'valid' and valid_epoch_acc > best_acc:\n",
    "                best_acc = valid_epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        history['train_acc'].append(train_epoch_acc.item())\n",
    "        history['train_los'].append(train_epoch_loss)\n",
    "        history['valid_acc'].append(valid_epoch_acc.item())\n",
    "        history['valid_los'].append(valid_epoch_loss)\n",
    "        \n",
    "        fmt_str = (\n",
    "            'Epoch [{:3d}/{:3d}] train loss: {:.4f} acc: {:.4f}'\n",
    "            ', valid loss: {:.4f} acc: {:.4f}'\n",
    "        )\n",
    "        print(fmt_str.format(\n",
    "            epoch, num_epochs - 1, \n",
    "            train_epoch_loss, train_epoch_acc, valid_epoch_loss, valid_epoch_acc\n",
    "        ))\n",
    "\n",
    "    print('\\nBest val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, best_acc, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [  0/  9] train loss: 0.2609 acc: 0.3801, valid loss: 0.2234 acc: 0.7271\n",
      "Epoch [  1/  9] train loss: 0.1871 acc: 0.6762, valid loss: 0.1572 acc: 0.7966\n",
      "Epoch [  2/  9] train loss: 0.1350 acc: 0.7608, valid loss: 0.1239 acc: 0.8333\n",
      "Epoch [  3/  9] train loss: 0.1018 acc: 0.8095, valid loss: 0.0968 acc: 0.8548\n",
      "Epoch [  4/  9] train loss: 0.0806 acc: 0.8316, valid loss: 0.0650 acc: 0.8753\n",
      "Epoch [  5/  9] train loss: 0.0683 acc: 0.8453, valid loss: 0.0588 acc: 0.8753\n",
      "Epoch [  6/  9] train loss: 0.0601 acc: 0.8551, valid loss: 0.0584 acc: 0.8856\n",
      "Epoch [  7/  9] train loss: 0.0553 acc: 0.8667, valid loss: 0.0571 acc: 0.8817\n",
      "Epoch [  8/  9] train loss: 0.0551 acc: 0.8654, valid loss: 0.0534 acc: 0.8841\n",
      "Epoch [  9/  9] train loss: 0.0543 acc: 0.8661, valid loss: 0.0516 acc: 0.8846\n",
      "\n",
      "Best val Acc: 0.885575\n",
      "Training time:   9.260539 minutes\n"
     ]
    }
   ],
   "source": [
    "NumEpochs = 10\n",
    "start_time = time.time()\n",
    "\n",
    "best_model, best_acc, history = train_model(\n",
    "    dataLoader, model, criterion, optimizer, exp_lr_scheduler, NumEpochs\n",
    ")\n",
    "    \n",
    "print('Training time: {:10f} minutes'.format((time.time()-start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'train_acc': [ 0.38009047508239746,\n",
      "                 0.6761648654937744,\n",
      "                 0.7607924342155457,\n",
      "                 0.8094655275344849,\n",
      "                 0.8316007852554321,\n",
      "                 0.8452977538108826,\n",
      "                 0.85508131980896,\n",
      "                 0.8666992783546448,\n",
      "                 0.8653540015220642,\n",
      "                 0.866087794303894],\n",
      "  'train_los': [ 0.2608551130881443,\n",
      "                 0.18712770494225703,\n",
      "                 0.13502974078374458,\n",
      "                 0.10182344710839994,\n",
      "                 0.08058808861493744,\n",
      "                 0.06832890985384392,\n",
      "                 0.06012564698539212,\n",
      "                 0.0553163445395334,\n",
      "                 0.05506136692341491,\n",
      "                 0.05426710446772809],\n",
      "  'valid_acc': [ 0.7271393537521362,\n",
      "                 0.7965770363807678,\n",
      "                 0.8332518339157104,\n",
      "                 0.8547677397727966,\n",
      "                 0.8753055930137634,\n",
      "                 0.8753055930137634,\n",
      "                 0.8855745792388916,\n",
      "                 0.8816626071929932,\n",
      "                 0.8841075897216797,\n",
      "                 0.884596586227417],\n",
      "  'valid_los': [ 0.22340146067090022,\n",
      "                 0.15721527684871608,\n",
      "                 0.1238532465652615,\n",
      "                 0.09683222007051948,\n",
      "                 0.06502312672458826,\n",
      "                 0.05876247984855857,\n",
      "                 0.05840560116219928,\n",
      "                 0.05710650073286957,\n",
      "                 0.0533863591972948,\n",
      "                 0.0516429766757564]}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(history, indent=2)\n",
    "\n",
    "train_acc = history['train_acc']\n",
    "train_los = history['train_los']\n",
    "valid_acc = history['valid_acc']\n",
    "valid_los = history['valid_los']\n",
    "\n",
    "# for i in range(len(history)):\n",
    "#     train_acc.append(history[i]['train_acc'])\n",
    "#     train_los.append(history[i]['train_loss'])\n",
    "#     valid_acc.append(history[i]['valid_acc'])\n",
    "#     valid_los.append(history[i]['valid_loss'])\n",
    "        \n",
    "def plot_lines(y1, y2, label=None, ax=None):\n",
    "    epochs = len(y1)\n",
    "    x = np.linspace(0, epochs, num=epochs)\n",
    "    ax.plot(x, y1, label=\"acc\")\n",
    "    ax.plot(x, y2, label=\"loss\")\n",
    "    # ax.set_title('training v.s. validate')\n",
    "    ax.set_title(label)\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_ylabel('Percentage')\n",
    "    \n",
    "    \n",
    "# 1. Plot in same line, this would work\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "\n",
    "ax1 = fig.add_subplot(1,2,1)\n",
    "plot_lines(train_acc, train_los, 'training', ax1)\n",
    "plt.legend()\n",
    "\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "plot_lines(valid_acc, valid_los, 'validate', ax2)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "currDT = datetime.now()\n",
    "currStr = currDT.strftime(\"%Y%m%d-%H%M\")\n",
    "\n",
    "acc_str = int(best_acc * 100)\n",
    "fname_best_model = 'resnet50_{}_acc{}.pth'.format(currStr, acc_str)\n",
    "\n",
    "best_model_wts = best_model.state_dict()\n",
    "\n",
    "PreTrainPath = Params['PreTrainPath']\n",
    "best_model_out = join(PreTrainPath, fname_best_model)\n",
    "\n",
    "torch.save(best_model_wts, best_model_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"DataPath\": \"/home/jovyan/data/dog-breed/\",\n",
      "    \"OutPath\": \"/home/jovyan/output/dog-breed/\",\n",
      "    \"ProcPath\": \"/home/jovyan/output/dog-breed/\",\n",
      "    \"PreTrainPath\": \"/home/jovyan/models/dog-breed/\",\n",
      "    \"PreTrainFile\": \"\",\n",
      "    \"TestPath\": \"/home/jovyan/data/dog-breed/test\",\n",
      "    \"TrainPath\": \"/home/jovyan/data/dog-breed/train\",\n",
      "    \"CsvLabel\": \"labels.csv\",\n",
      "    \"BatchSize\": 16,\n",
      "    \"FracForTrain\": 0.8\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Save parameters to json file\n",
    "\n",
    "fname = 'Params_{}.json'.format(currStr)\n",
    "\n",
    "OutPath = Params['OutPath']\n",
    "f_abspath = join(OutPath, fname)\n",
    "\n",
    "json_str = json.dumps(Params, indent=4)\n",
    "print(json_str)\n",
    "\n",
    "with open(f_abspath, 'w') as fout:\n",
    "    fout.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"scottish_deerhound\": 0,\n",
      "    \"maltese_dog\": 1,\n",
      "    \"afghan_hound\": 2,\n",
      "    \"entlebucher\": 3,\n",
      "    \"bernese_mountain_dog\": 4,\n",
      "    \"shih-tzu\": 5,\n",
      "    \"great_pyrenees\": 6,\n",
      "    \"pomeranian\": 7,\n",
      "    \"basenji\": 8,\n",
      "    \"samoyed\": 9,\n",
      "    \"airedale\": 10,\n",
      "    \"tibetan_terrier\": 11,\n",
      "    \"leonberg\": 12,\n",
      "    \"cairn\": 13,\n",
      "    \"beagle\": 14,\n",
      "    \"japanese_spaniel\": 15,\n",
      "    \"australian_terrier\": 16,\n",
      "    \"blenheim_spaniel\": 17,\n",
      "    \"miniature_pinscher\": 18,\n",
      "    \"irish_wolfhound\": 19,\n",
      "    \"lakeland_terrier\": 20,\n",
      "    \"saluki\": 21,\n",
      "    \"papillon\": 22,\n",
      "    \"whippet\": 23,\n",
      "    \"siberian_husky\": 24,\n",
      "    \"norwegian_elkhound\": 25,\n",
      "    \"pug\": 26,\n",
      "    \"chow\": 27,\n",
      "    \"italian_greyhound\": 28,\n",
      "    \"pembroke\": 29,\n",
      "    \"ibizan_hound\": 30,\n",
      "    \"border_terrier\": 31,\n",
      "    \"newfoundland\": 32,\n",
      "    \"lhasa\": 33,\n",
      "    \"silky_terrier\": 34,\n",
      "    \"bedlington_terrier\": 35,\n",
      "    \"dandie_dinmont\": 36,\n",
      "    \"irish_setter\": 37,\n",
      "    \"sealyham_terrier\": 38,\n",
      "    \"rhodesian_ridgeback\": 39,\n",
      "    \"old_english_sheepdog\": 40,\n",
      "    \"collie\": 41,\n",
      "    \"boston_bull\": 42,\n",
      "    \"english_foxhound\": 43,\n",
      "    \"bouvier_des_flandres\": 44,\n",
      "    \"african_hunting_dog\": 45,\n",
      "    \"schipperke\": 46,\n",
      "    \"kelpie\": 47,\n",
      "    \"weimaraner\": 48,\n",
      "    \"bloodhound\": 49,\n",
      "    \"bluetick\": 50,\n",
      "    \"saint_bernard\": 51,\n",
      "    \"labrador_retriever\": 52,\n",
      "    \"chesapeake_bay_retriever\": 53,\n",
      "    \"norfolk_terrier\": 54,\n",
      "    \"english_setter\": 55,\n",
      "    \"wire-haired_fox_terrier\": 56,\n",
      "    \"kerry_blue_terrier\": 57,\n",
      "    \"scotch_terrier\": 58,\n",
      "    \"yorkshire_terrier\": 59,\n",
      "    \"groenendael\": 60,\n",
      "    \"greater_swiss_mountain_dog\": 61,\n",
      "    \"irish_terrier\": 62,\n",
      "    \"basset\": 63,\n",
      "    \"keeshond\": 64,\n",
      "    \"west_highland_white_terrier\": 65,\n",
      "    \"gordon_setter\": 66,\n",
      "    \"malamute\": 67,\n",
      "    \"affenpinscher\": 68,\n",
      "    \"toy_poodle\": 69,\n",
      "    \"clumber\": 70,\n",
      "    \"mexican_hairless\": 71,\n",
      "    \"dingo\": 72,\n",
      "    \"standard_poodle\": 73,\n",
      "    \"miniature_poodle\": 74,\n",
      "    \"staffordshire_bullterrier\": 75,\n",
      "    \"welsh_springer_spaniel\": 76,\n",
      "    \"toy_terrier\": 77,\n",
      "    \"sussex_spaniel\": 78,\n",
      "    \"norwich_terrier\": 79,\n",
      "    \"appenzeller\": 80,\n",
      "    \"irish_water_spaniel\": 81,\n",
      "    \"miniature_schnauzer\": 82,\n",
      "    \"black-and-tan_coonhound\": 83,\n",
      "    \"cardigan\": 84,\n",
      "    \"dhole\": 85,\n",
      "    \"shetland_sheepdog\": 86,\n",
      "    \"rottweiler\": 87,\n",
      "    \"english_springer\": 88,\n",
      "    \"great_dane\": 89,\n",
      "    \"german_short-haired_pointer\": 90,\n",
      "    \"boxer\": 91,\n",
      "    \"bull_mastiff\": 92,\n",
      "    \"borzoi\": 93,\n",
      "    \"pekinese\": 94,\n",
      "    \"cocker_spaniel\": 95,\n",
      "    \"american_staffordshire_terrier\": 96,\n",
      "    \"doberman\": 97,\n",
      "    \"brittany_spaniel\": 98,\n",
      "    \"malinois\": 99,\n",
      "    \"standard_schnauzer\": 100,\n",
      "    \"flat-coated_retriever\": 101,\n",
      "    \"redbone\": 102,\n",
      "    \"border_collie\": 103,\n",
      "    \"curly-coated_retriever\": 104,\n",
      "    \"kuvasz\": 105,\n",
      "    \"chihuahua\": 106,\n",
      "    \"soft-coated_wheaten_terrier\": 107,\n",
      "    \"french_bulldog\": 108,\n",
      "    \"vizsla\": 109,\n",
      "    \"tibetan_mastiff\": 110,\n",
      "    \"german_shepherd\": 111,\n",
      "    \"giant_schnauzer\": 112,\n",
      "    \"walker_hound\": 113,\n",
      "    \"otterhound\": 114,\n",
      "    \"golden_retriever\": 115,\n",
      "    \"brabancon_griffon\": 116,\n",
      "    \"komondor\": 117,\n",
      "    \"briard\": 118,\n",
      "    \"eskimo_dog\": 119\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Save breed dict to json file\n",
    "fname = 'BreedDict_{}.json'.format(currStr)\n",
    "f_abspath = join(OutPath, fname)\n",
    "\n",
    "json_str = json.dumps(dict_bid_fw, indent=4)\n",
    "print(json_str)\n",
    "\n",
    "with open(f_abspath, 'w') as fout:\n",
    "    fout.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
